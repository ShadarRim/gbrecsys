{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вебинар 6. Двухуровневые модели рекомендаций\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для src, utils, metrics вы можете скачать из [этого](https://github.com/geangohn/recsys-tutorial) github репозитория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Написанные нами функции\n",
    "from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "from src.recomenders import MainRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import ItemItemRecommender  # нужен для одного трюка\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "\n",
    "class MainRecommender_nb:\n",
    "\n",
    "    \"\"\"Рекоммендации, которые можно получить из ALS\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    user_item_matrix: pd.DataFrame\n",
    "        Матрица взаимодействий user-item\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, weighting=True):\n",
    "    \n",
    "        # нам потребуется топ покупок для каждого user\n",
    "        self.top_purchases = data.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n",
    "        self.top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
    "        #не забываем удалять 999999, иначе всё не слава богу\n",
    "        self.top_purchases = self.top_purchases[self.top_purchases['item_id'] != 999999]\n",
    "    \n",
    "        # нам потребуется список всех покупок\n",
    "        self.all_top_purchases = data.groupby('item_id')['quantity'].count().reset_index()\n",
    "        self.all_top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
    "        # так как мы создавали 999999, то его надо удалить, иначе всё не слава богу\n",
    "        self.all_top_purchases = self.all_top_purchases[self.all_top_purchases['item_id'] != 999999]\n",
    "        self.all_top_purchases = self.all_top_purchases.item_id.tolist()\n",
    "        \n",
    "        # your_code. Это не обязательная часть. Но если вам удобно что-либо посчитать тут - можно это сделать\n",
    "        \n",
    "        self.user_item_matrix = self.prepare_matrix(data)  # pd.DataFrame\n",
    "        self.id_to_itemid, self.id_to_userid, self.itemid_to_id, self.userid_to_id = self.prepare_dicts(self.user_item_matrix)\n",
    "        \n",
    "        if weighting:\n",
    "            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T \n",
    "        \n",
    "        self.model = self.fit(self.user_item_matrix)\n",
    "        self.own_recommender = self.fit_own_recommender(self.user_item_matrix)\n",
    "     \n",
    "    @staticmethod\n",
    "    def prepare_matrix(data):\n",
    "        \n",
    "        user_item_matrix = pd.pivot_table(data,\n",
    "                                          index='user_id', columns='item_id',\n",
    "                                          values='quantity',  \n",
    "                                          aggfunc='count',\n",
    "                                          fill_value=0\n",
    "                                          )\n",
    "\n",
    "        user_item_matrix = user_item_matrix.astype(float)\n",
    "        \n",
    "        return user_item_matrix\n",
    "    \n",
    "    #@staticmethod\n",
    "    def prepare_dicts(self, user_item_matrix):\n",
    "        \"\"\"Подготавливает вспомогательные словари\"\"\"\n",
    "        \n",
    "        userids = user_item_matrix.index.values\n",
    "        itemids = user_item_matrix.columns.values\n",
    "\n",
    "        matrix_userids = np.arange(len(userids))\n",
    "        matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "        id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "        userid_to_id = dict(zip(userids, matrix_userids))\n",
    "        \n",
    "        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n",
    "     \n",
    "    @staticmethod\n",
    "    def fit_own_recommender(user_item_matrix):\n",
    "        \"\"\"Обучает модель, которая рекомендует товары, среди товаров, купленных юзером\"\"\"\n",
    "    \n",
    "        own_recommender = ItemItemRecommender(K=1, num_threads=4)\n",
    "        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        \n",
    "        return own_recommender\n",
    "    \n",
    "    @staticmethod\n",
    "    def fit(user_item_matrix, n_factors=20, regularization=0.001, iterations=15, num_threads=4):\n",
    "        \"\"\"Обучает ALS\"\"\"\n",
    "        \n",
    "        model = AlternatingLeastSquares(factors=n_factors, \n",
    "                                             regularization=regularization,\n",
    "                                             iterations=iterations,  \n",
    "                                             num_threads=num_threads)\n",
    "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _get_similar_item(self, item_id):\n",
    "        \"\"\"Находит товар, похожий на item_id\"\"\"\n",
    "        recs = self.model.similar_items(self.itemid_to_id[item_id], N=2)  # Товар похож на себя -> рекомендуем 2 товара\n",
    "        top_rec = recs[1][0]  # И берем второй (не товар из аргумента метода)\n",
    "        return self.id_to_itemid[top_rec]\n",
    "\n",
    "    def _extend_with_top_popular(self, recommendations, N=5):\n",
    "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
    "\n",
    "        if len(recommendations) < N:\n",
    "            recommendations.extend(self.overall_top_purchases[:N])\n",
    "            recommendations = recommendations[:N]\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "    def _update_dict(self, user_id):\n",
    "        \"\"\"Если появился новыю user / item, то нужно обновить словари\"\"\"\n",
    "\n",
    "        if user_id not in self.userid_to_id.keys():\n",
    "\n",
    "            max_id = max(list(self.userid_to_id.values()))\n",
    "            max_id += 1\n",
    "\n",
    "            self.userid_to_id.update({user_id: max_id})\n",
    "            self.id_to_userid.update({max_id: user_id})\n",
    "            \n",
    "    def _get_recommendations(self, user, model, N=5):\n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "        \n",
    "        #print(self.itemid_to_id)\n",
    "\n",
    "        self._update_dict(user_id=user)\n",
    "        res = [self.id_to_itemid[rec[0]] for rec in model.recommend(userid=self.userid_to_id[user],\n",
    "                                        user_items=csr_matrix(self.user_item_matrix).tocsr(),\n",
    "                                        N=N,\n",
    "                                        filter_already_liked_items=False,\n",
    "                                        filter_items=[], #self.itemid_to_id[999999]],\n",
    "                                        recalculate_user=True)]\n",
    "\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "\n",
    "    \n",
    "    def get_als_recommendations(self, user, N=5):\n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "\n",
    "        self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.model, N=N)\n",
    "\n",
    "    def get_own_recommendations(self, user, N=5):\n",
    "        \"\"\"Рекомендуем товары среди тех, которые юзер уже купил\"\"\"\n",
    "\n",
    "        self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.own_recommender, N=N)\n",
    "\n",
    "    def get_similar_items_recommendation(self, user, N=5):\n",
    "        \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
    "\n",
    "        top_N_u_purchases = self.top_purchases[self.top_purchases['user_id'] == user].head(N)\n",
    "\n",
    "        res = top_N_u_purchases['item_id'].apply(lambda x: self._get_similar_item(x)).tolist()\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "        \n",
    "        if len(res) < N:\n",
    "            #придётся дополнитеь список, чтобы всегда иметь одинаковое количество товаров\n",
    "            #будет добавлять товары до нужно размера из общего рейтинга покупок, который для этго придётся делать\n",
    "            #можно и случайно, конечно, но кажется, что так точнее\n",
    "            res.extend(self.all_top_purchases[:N])\n",
    "            res = res[:N]\n",
    "\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "    \n",
    "    def get_similar_users_recommendation(self, user, N=5):\n",
    "    \n",
    "    #\"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
    "    \n",
    "        res = []\n",
    "\n",
    "       \n",
    "        sim_users = self.model.similar_users(self.userid_to_id[user], N=N+1)\n",
    "        sim_users = [rec[0] for rec in sim_users]\n",
    "        sim_users = sim_users[1:]   # сам user тоже найдётся как похожий\n",
    "\n",
    "        for user in sim_users:\n",
    "            res.extend(self.get_own_recommendations(user, N=1))\n",
    "\n",
    "\n",
    "        if len(res) < N:\n",
    "            #придётся дополнитеь список, чтобы всегда иметь одинаковое количество товаров\n",
    "            #будет добавлять товары до нужно размера из общего рейтинга покупок, который для этго придётся делать\n",
    "            #можно и случайно, конечно, но кажется, что так точнее\n",
    "            res.extend(self.all_top_purchases[:N])\n",
    "            res = res[:N]\n",
    "\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prefilter_items_nb(data, take_n_popular=5000, item_features=None):\n",
    "    # Уберем самые популярные товары (их и так купят)\n",
    "    popularity = data.groupby('item_id')['user_id'].nunique().reset_index() / data['user_id'].nunique()\n",
    "    popularity.rename(columns={'user_id': 'share_unique_users'}, inplace=True)\n",
    "    \n",
    "    top_popular = popularity[popularity['share_unique_users'] > 0.5].item_id.tolist()\n",
    "    data = data[~data['item_id'].isin(top_popular)]\n",
    "    \n",
    "    # Уберем самые НЕ популярные товары (их и так НЕ купят)\n",
    "    top_notpopular = popularity[popularity['share_unique_users'] < 0.01].item_id.tolist()\n",
    "    data = data[~data['item_id'].isin(top_notpopular)]\n",
    "    \n",
    "    # Уберем товары, которые не продавались за последние 12 месяцев\n",
    "    \n",
    "    # Уберем не интересные для рекоммендаций категории (department)\n",
    "    \n",
    "    if item_features is not None:\n",
    "        department_size = pd.DataFrame(item_features.groupby('department')['item_id'].nunique().sort_values(ascending=False)).reset_index()\n",
    "\n",
    "        department_size.columns = ['department', 'n_items']\n",
    "        rare_departments = department_size[department_size['n_items'] < 100].department.tolist()\n",
    "        items_in_rare_departments = item_features[item_features['department'].isin(rare_departments)].item_id.unique().tolist()\n",
    "\n",
    "        data = data[~data['item_id'].isin(items_in_rare_departments)]\n",
    "    \n",
    "    # Уберем слишком дешевые товары (на них не заработаем). 1 покупка из рассылок стоит 60 руб. \n",
    "    \n",
    "    data['price'] = data['sales_value'] / (np.maximum(data['quantity'], 1))\n",
    "    data = data[data['price'] > 5]\n",
    "    \n",
    "    # Уберем слишком дорогие товарыs\n",
    "    data = data[data['price'] < 100]\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def postfilter_items(user_id, recommednations):\n",
    "    pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('retail_train.csv')\n",
    "item_features = pd.read_csv('product.csv')\n",
    "user_features = pd.read_csv('hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 18351 to 18351\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "data_train_lvl_1 = prefilter_items_nb(data_train_lvl_1, take_n_popular=5000, item_features=item_features)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a4d288dca34710adf36c1748dc8182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93ef5d61495414f848a949ee26a9bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18351), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommender = MainRecommender_nb(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1085346, 843076, 908088, 868645, 836587]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_als_recommendations(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12673175, 15927673, 8068801, 5567226, 885468]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_own_recommendations(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[985000, 10198378, 854405, 1018740, 1000753]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_items_recommendation(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1019740, 12810279, 6396292, 8203731, 1066620]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_users_recommendation(2375, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
    "- Пока пробуем отобрать 50 кандидатов (k=50)\n",
    "- Качество измеряем на data_val_lvl_1: следующие 6 недель после трейна\n",
    "\n",
    "Дают ли own recommendtions + top-popular лучший recall?  \n",
    "\n",
    "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}  \n",
    "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
       "1        2  [15830248, 838136, 839656, 861272, 866211, 870..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_1.columns=['user_id', 'actual']\n",
    "result_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.\n",
    "\n",
    "Обучите модель 2-ого уровня, при этом:\n",
    "    - Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар\n",
    "    - Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_lvl_2\n",
    "    - Вырос ли precision@5 при использовании двухуровневой модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Финальный проект\n",
    "\n",
    "Мы уже прошли всю необходимуб теорию для финального проекта. Проект осуществляется на данных из вебинара (данные считаны в начале ДЗ).\n",
    "Рекомендуем вам **начать делать проект сразу после этого домашнего задания**\n",
    "- Целевая метрика - precision@5. Порог для уcпешной сдачи проекта precision@5 > 0.27%\n",
    "- Будет public тестовый датасет, на котором вы сможете измерять метрику\n",
    "- Также будет private тестовый датасет для измерения финального качества\n",
    "- НЕ обязательно, но крайне желательно использовать 2-ух уровневые рекоммендательные системы в проекте\n",
    "- Вы сдаете код проекта в виде github репозитория и csv файл с рекомендациями "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
